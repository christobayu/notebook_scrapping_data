{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14c5b0da-6672-4169-be61-548240015474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8490975d-87ac-499c-813b-586f2e9a9c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False,nb_workers=2)\n",
    "\n",
    "from pandas import json_normalize\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import gspread as gs\n",
    "\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37efe10-def4-4258-a9ce-0c8e361e7e62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import MyFunc\n",
    "# from MyFunc import cleaning_data_merchants,filtering_data_merchants,get_post_code,upload_file_to_GCS,create_table_from_gcs,is_on_radius,get_hot_area\n",
    "from MyFunc import *\n",
    "\n",
    "from importlib import reload\n",
    "reload(MyFunc)\n",
    "from MyFunc import *\n",
    "# cleaning_data_merchants,filtering_data_merchants,get_post_code,upload_file_to_GCS,create_table_from_gcs,is_on_radius,get_hot_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c08721-1efd-4bf0-97e0-e80a791a5085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.auth\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('Horego-GCP-Keys.json')\n",
    "project_id = 'cashbac-31433'\n",
    "\n",
    "# Make clients.\n",
    "cashbac_bqclient = bigquery.Client(\n",
    "    credentials=credentials,\n",
    "    project=project_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf7f5fbb-0237-48de-a322-32d2b4aedb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "query_string=f\"\"\" \n",
    "\n",
    "SELECT column_name\n",
    "FROM cashbac-31433.cashbac_datalake_prod.INFORMATION_SCHEMA.COLUMNS\n",
    "WHERE table_name = 'outcrapper_google_results_raw'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_result = list(cashbac_bqclient.query(query_string).result(timeout=None))\n",
    "print(len(query_result))\n",
    "if len(query_result)>0:\n",
    "    df_temp = pd.DataFrame(data=[list(x.values()) for x in query_result], columns=list(query_result[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877cd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string=f\"\"\" \n",
    "\n",
    "SELECT * \n",
    "FROM `cashbac-31433.cashbac_datalake_prod.daftar_kota_admin_level_kelurahan_with_lat_long`\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_result = list(cashbac_bqclient.query(query_string).result(timeout=None))\n",
    "print(len(query_result))\n",
    "if len(query_result)>0:\n",
    "    data_location = pd.DataFrame(data=[list(x.values()) for x in query_result], columns=list(query_result[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd5a895-50da-441c-aa8e-80701e2a0299",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202312071014266b2e_places_outlet_submission_7_des.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debe7bc40d914c64b021b7bbfd9d5084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=13), Label(value='0 / 13'))), HBoxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading results/temp_upload_raw.csv\n",
      "Path in GCS: cashbac_datalake/scrapping_results/raw/202312071014266b2e_places_outlet_submission_7_des.csv\n",
      "table on : cashbac_datalake_prod.outcrapper_google_results_raw\n",
      "DONE\n",
      "CPU times: user 255 ms, sys: 63.1 ms, total: 318 ms\n",
      "Wall time: 4.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "cashbac_key='Cashbac-GCP-Keys.json'\n",
    "horego_key='Horego-GCP-Keys.json'\n",
    "\n",
    "scrappe_date='20231207'\n",
    "        \n",
    "# data_location=pd.read_csv('daftar_kota_admin_level_kelurahan_with_lat_long.csv',sep=';')\n",
    "# data_location=data_location[(data_location.latitude<=6) &(data_location.latitude>=-11)&(data_location.longitude>=95)&(data_location.longitude<=141)]\n",
    "# data_location=data_location[data_location.Province.str.contains('Jakarta|Jawa|Banten|Yogyakarta')]\n",
    "\n",
    "# df_temp=pd.read_csv('results/clear_raw_table.csv',sep=';', nrows=1)\n",
    "# my_schema=[]\n",
    "# for column in df_temp.columns :\n",
    "#     if column in ['working_hours','about']:\n",
    "#         my_schema.append(bigquery.SchemaField(column, \"JSON\"))\n",
    "#     else:\n",
    "#         my_schema.append(bigquery.SchemaField(column, \"STRING\"))\n",
    "\n",
    "path = 'outcrapper_raw/merchant_list/'\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if os.path.isfile(path+'/'+f)]\n",
    "files.sort()\n",
    "\n",
    "for file in files:\n",
    "    if '.json' in file and int(file[:8])>=int(scrappe_date):\n",
    "        print(file)\n",
    "        f = open(f'{path}{file}')\n",
    "        data = json.load(f)\n",
    "        data = pd.DataFrame.from_dict(data)\n",
    "        data = data[data.place_id!='__NO_PLACE_FOUND__']\n",
    "        \n",
    "        data['outcrapper_job_id']=file.split('_')[0]\n",
    "        data['scrappe_date'] = datetime.strptime(file[:8], '%Y%m%d').strftime('%Y-%m-%d')\n",
    "        data=cleaning_data_merchants(data)\n",
    "        \n",
    "        # data=filtering_data_merchants(data,'Cashbac-GCP-Keys.json')\n",
    "        \n",
    "        data[['kodepos','province','kabupaten','kecamatan','kelurahan']]=data.parallel_apply(lambda x: get_post_code(x.longitude,x.latitude,data_location),axis=1)\n",
    "        \n",
    "        my_schema=[]\n",
    "        save_columns=[]\n",
    "        for column in df_temp.column_name :\n",
    "            if column in data.columns :\n",
    "                save_columns.append(column)\n",
    "                if column in ['working_hours','about']:\n",
    "                    my_schema.append(bigquery.SchemaField(column, \"JSON\"))\n",
    "                else:\n",
    "                    my_schema.append(bigquery.SchemaField(column, \"STRING\"))\n",
    "        data[save_columns].to_csv('results/temp_upload_raw.csv',sep=';',index=False)\n",
    "        \n",
    "        #############################################################################################\n",
    "        #BQ DATALAKE HOREGO\n",
    "        # src_path_file='results/temp_upload_raw.csv'\n",
    "        # target_path_file=f\"scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        # bucket_name='horego-bq'\n",
    "        # upload_file_to_GCS(horego_key,bucket_name,src_path_file,target_path_file)\n",
    "\n",
    "        # table_schema = \"horego_datalake_dev\"\n",
    "        # table_name = \"outcrapper_google_results_raw\"\n",
    "        # gcs_path_uri = f\"gs://{bucket_name}/scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        # create_table_from_gcs(horego_key,gcs_path_uri,table_schema,table_name,my_schema,'append')\n",
    "        \n",
    "        #############################################################################################\n",
    "        #############################################################################################\n",
    "        #BQ DATALAKE CASHBAC\n",
    "        bucket_name='cashbac_datalake'\n",
    "        src_path_file='results/temp_upload_raw.csv'\n",
    "        target_path_file=f\"scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        upload_file_to_GCS(horego_key,bucket_name,src_path_file,target_path_file)\n",
    "\n",
    "        table_schema = \"cashbac_datalake_prod\"\n",
    "        table_name = \"outcrapper_google_results_raw\"\n",
    "        gcs_path_uri = f\"gs://{bucket_name}/scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        create_table_from_gcs(horego_key,gcs_path_uri,table_schema,table_name,my_schema,'append')\n",
    "        #############################################################################################\n",
    "        \n",
    "        \n",
    "path = 'outcrapper_raw/popular_brands/'\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if os.path.isfile(path+'/'+f)]\n",
    "files.sort()\n",
    "\n",
    "for file in files:\n",
    "    if '.json' in file and int(file[:8])>=int(scrappe_date):\n",
    "        print(file)\n",
    "        f = open(f'{path}{file}')\n",
    "        data = json.load(f)\n",
    "        data = pd.DataFrame.from_dict(data)\n",
    "        data = data[data.place_id!='__NO_PLACE_FOUND__']\n",
    "        \n",
    "        data['outcrapper_job_id']=file.split('_')[0]\n",
    "        data['scrappe_date'] = datetime.strptime(file[:8], '%Y%m%d').strftime('%Y-%m-%d')\n",
    "        data=cleaning_data_merchants(data)\n",
    "        \n",
    "        # data=filtering_data_merchants(data,'Cashbac-GCP-Keys.json')\n",
    "        \n",
    "        data[['kodepos','province','kabupaten','kecamatan','kelurahan']]=data.parallel_apply(lambda x: get_post_code(x.longitude,x.latitude,data_location),axis=1)\n",
    "        my_schema=[]\n",
    "        save_columns=[]\n",
    "        for column in df_temp.column_name :\n",
    "            if column in data.columns :\n",
    "                save_columns.append(column)\n",
    "                if column in ['working_hours','about']:\n",
    "                    my_schema.append(bigquery.SchemaField(column, \"JSON\"))\n",
    "                else:\n",
    "                    my_schema.append(bigquery.SchemaField(column, \"STRING\"))\n",
    "        data[save_columns].to_csv('results/temp_upload_raw.csv',sep=';',index=False)\n",
    "        \n",
    "        #############################################################################################\n",
    "        #BQ DATALAKE HOREGO\n",
    "        # src_path_file='results/temp_upload_raw.csv'\n",
    "        # target_path_file=f\"scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        # bucket_name='horego-bq'\n",
    "        # upload_file_to_GCS(horego_key,bucket_name,src_path_file,target_path_file)\n",
    "\n",
    "        # table_schema = \"horego_datalake_dev\"\n",
    "        # table_name = \"outcrapper_google_results_raw\"\n",
    "        # gcs_path_uri = f\"gs://{bucket_name}/scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        # create_table_from_gcs(horego_key,gcs_path_uri,table_schema,table_name,my_schema,'append')\n",
    "        \n",
    "        #############################################################################################\n",
    "        #############################################################################################\n",
    "        #BQ DATALAKE CASHBAC\n",
    "        bucket_name='cashbac_datalake'\n",
    "        src_path_file='results/temp_upload_raw.csv'\n",
    "        target_path_file=f\"scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        upload_file_to_GCS(horego_key,bucket_name,src_path_file,target_path_file)\n",
    "\n",
    "        table_schema = \"cashbac_datalake_prod\"\n",
    "        table_name = \"outcrapper_google_results_raw\"\n",
    "        gcs_path_uri = f\"gs://{bucket_name}/scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        create_table_from_gcs(horego_key,gcs_path_uri,table_schema,table_name,my_schema,'append')\n",
    "        #############################################################################################\n",
    "\n",
    "\n",
    "path = 'outcrapper_raw/merchant_list_no_filter/'\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if os.path.isfile(path+'/'+f)]\n",
    "files.sort()\n",
    "\n",
    "for file in files:\n",
    "    if '.json' in file and int(file[:8])>=int(scrappe_date):\n",
    "        print(file)\n",
    "        f = open(f'{path}{file}')\n",
    "        data = json.load(f)\n",
    "        data = pd.DataFrame.from_dict(data)\n",
    "        data = data[data.place_id!='__NO_PLACE_FOUND__']\n",
    "        \n",
    "        data['outcrapper_job_id']=file.split('_')[0]\n",
    "        data['scrappe_date'] = datetime.strptime(file[:8], '%Y%m%d').strftime('%Y-%m-%d')\n",
    "        data=cleaning_data_merchants(data)\n",
    "        \n",
    "        # data=filtering_data_merchants(data,'Cashbac-GCP-Keys.json')\n",
    "        \n",
    "        data[['kodepos','province','kabupaten','kecamatan','kelurahan']]=data.parallel_apply(lambda x: get_post_code(x.longitude,x.latitude,data_location),axis=1)\n",
    "        \n",
    "        my_schema=[]\n",
    "        save_columns=[]\n",
    "        for column in df_temp.column_name :\n",
    "            if column in data.columns :\n",
    "                save_columns.append(column)\n",
    "                if column in ['working_hours','about']:\n",
    "                    my_schema.append(bigquery.SchemaField(column, \"JSON\"))\n",
    "                else:\n",
    "                    my_schema.append(bigquery.SchemaField(column, \"STRING\"))\n",
    "        data[save_columns].to_csv('results/temp_upload_raw.csv',sep=';',index=False)\n",
    "        \n",
    "        #############################################################################################\n",
    "        #BQ DATALAKE HOREGO\n",
    "        # src_path_file='results/temp_upload_raw.csv'\n",
    "        # target_path_file=f\"scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        # bucket_name='horego-bq'\n",
    "        # upload_file_to_GCS(horego_key,bucket_name,src_path_file,target_path_file)\n",
    "\n",
    "        # table_schema = \"horego_datalake_dev\"\n",
    "        # table_name = \"outcrapper_google_results_raw\"\n",
    "        # gcs_path_uri = f\"gs://{bucket_name}/scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        # create_table_from_gcs(horego_key,gcs_path_uri,table_schema,table_name,my_schema,'append')\n",
    "        \n",
    "        #############################################################################################\n",
    "        #############################################################################################\n",
    "        #BQ DATALAKE CASHBAC\n",
    "        bucket_name='cashbac_datalake'\n",
    "        src_path_file='results/temp_upload_raw.csv'\n",
    "        target_path_file=f\"scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        upload_file_to_GCS(horego_key,bucket_name,src_path_file,target_path_file)\n",
    "\n",
    "        table_schema = \"cashbac_datalake_prod\"\n",
    "        table_name = \"outcrapper_google_results_raw\"\n",
    "        gcs_path_uri = f\"gs://{bucket_name}/scrapping_results/raw/{file.replace('.json','.csv')}\"\n",
    "        create_table_from_gcs(horego_key,gcs_path_uri,table_schema,table_name,my_schema,'append')\n",
    "        #############################################################################################\n",
    "\n",
    "del data        \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a169d-a8f9-4324-863a-4bd3a6f3a684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
