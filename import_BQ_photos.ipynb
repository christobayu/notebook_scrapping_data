{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b11654a-e077-420e-a329-f160541d0b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a837f72-9fc9-4eea-976c-d242607274d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "from imageai.Classification import ImageClassification\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False,nb_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5242b49c-8785-4c0a-8a33-4a22515736d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.auth\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('Cashbac-GCP-Keys.json')\n",
    "project_id = 'cashbac-31433'\n",
    "\n",
    "# Make clients.\n",
    "cashbac_bqclient = bigquery.Client(\n",
    "    credentials=credentials,\n",
    "    project=project_id,\n",
    ")\n",
    "\n",
    "import google.auth\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('Horego-GCP-Keys.json')\n",
    "project_id = 'horego-big-query'\n",
    "\n",
    "# Make clients.\n",
    "horego_bqclient = bigquery.Client(\n",
    "    credentials=credentials,\n",
    "    project=project_id,\n",
    ")\n",
    "\n",
    "import psycopg2.pool\n",
    "def db_connect_cashbac_nopool(host,database,user,password):\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    connection = psycopg2.connect(host=host,\n",
    "                              database=database,\n",
    "                              user=user,\n",
    "                              password=password,\n",
    "                              port=5432)\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb21cd-cf7e-4d77-a8f3-8e1d710484f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# IMPORT BQ NEW WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "459caa0e-b4d1-42e4-891f-e2c3fffd8a27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import MyFunc\n",
    "# from MyFunc import cleaning_data_merchants,filtering_data_merchants,get_post_code,upload_file_to_GCS,create_table_from_gcs,is_on_radius,get_hot_area\n",
    "from MyFunc import *\n",
    "\n",
    "from importlib import reload\n",
    "reload(MyFunc)\n",
    "from MyFunc import *\n",
    "# cleaning_data_merchants,filtering_data_merchants,get_post_code,upload_file_to_GCS,create_table_from_gcs,is_on_radius,get_hot_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691fd293-e09b-4a7c-a430-08844ead09d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "CPU times: user 53.8 ms, sys: 26.9 ms, total: 80.6 ms\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query_string=f\"\"\" \n",
    "\n",
    "SELECT * \n",
    "FROM `cashbac-31433.cashbac_datalake_prod.outcrapper_google_photos` table1\n",
    "limit 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_result = list(cashbac_bqclient.query(query_string).result(timeout=None))\n",
    "print(len(query_result))\n",
    "if len(query_result)>0:\n",
    "    df_temp = pd.DataFrame(data=[list(x.values()) for x in query_result], columns=list(query_result[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23ffeb3-4035-4846-ba46-a5571179209e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20231114022617792f_photos_places_with_no_photos_jakut_jakbar_jakpus.json\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: horego-bq/scrapping_results/photos/20231114022617792f_photos_places_with_no_photos_jakut_jakbar_jakpus.csv\n",
      "table on : horego_datalake_dev.outcrapper_google_photos\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: cashbac_datalake/scrapping_results/photos/20231114022617792f_photos_places_with_no_photos_jakut_jakbar_jakpus.csv\n",
      "table on : cashbac_datalake_prod.outcrapper_google_photos\n",
      "20231114022842e088_photos_places_with_no_photo_menus_jaktim_-_jaksel.json\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: horego-bq/scrapping_results/photos/20231114022842e088_photos_places_with_no_photo_menus_jaktim_-_jaksel.csv\n",
      "table on : horego_datalake_dev.outcrapper_google_photos\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: cashbac_datalake/scrapping_results/photos/20231114022842e088_photos_places_with_no_photo_menus_jaktim_-_jaksel.csv\n",
      "table on : cashbac_datalake_prod.outcrapper_google_photos\n",
      "202311140231446bc6_photos_places_with_no_photo_menu_bekasi_-_depok.json\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: horego-bq/scrapping_results/photos/202311140231446bc6_photos_places_with_no_photo_menu_bekasi_-_depok.csv\n",
      "table on : horego_datalake_dev.outcrapper_google_photos\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: cashbac_datalake/scrapping_results/photos/202311140231446bc6_photos_places_with_no_photo_menu_bekasi_-_depok.csv\n",
      "table on : cashbac_datalake_prod.outcrapper_google_photos\n",
      "202311140232596252_photos_places_with_no_photo_menu_tangerang_tangsel.json\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: horego-bq/scrapping_results/photos/202311140232596252_photos_places_with_no_photo_menu_tangerang_tangsel.csv\n",
      "table on : horego_datalake_dev.outcrapper_google_photos\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: cashbac_datalake/scrapping_results/photos/202311140232596252_photos_places_with_no_photo_menu_tangerang_tangsel.csv\n",
      "table on : cashbac_datalake_prod.outcrapper_google_photos\n",
      "202311140235128592_photos_places_with_no_photos_menu_bogor_-_cimahi.json\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: horego-bq/scrapping_results/photos/202311140235128592_photos_places_with_no_photos_menu_bogor_-_cimahi.csv\n",
      "table on : horego_datalake_dev.outcrapper_google_photos\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: cashbac_datalake/scrapping_results/photos/202311140235128592_photos_places_with_no_photos_menu_bogor_-_cimahi.csv\n",
      "table on : cashbac_datalake_prod.outcrapper_google_photos\n",
      "202311140236185ac7_photos_places_with_no_photos_bandung.json\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: horego-bq/scrapping_results/photos/202311140236185ac7_photos_places_with_no_photos_bandung.csv\n",
      "table on : horego_datalake_dev.outcrapper_google_photos\n",
      "Uploading results/temp_upload_photos.csv\n",
      "Path in GCS: cashbac_datalake/scrapping_results/photos/202311140236185ac7_photos_places_with_no_photos_bandung.csv\n",
      "table on : cashbac_datalake_prod.outcrapper_google_photos\n",
      "CPU times: user 5.07 s, sys: 824 ms, total: 5.89 s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "cashbac_key='Cashbac-GCP-Keys.json'\n",
    "horego_key='Horego-GCP-Keys.json'\n",
    "\n",
    "scrappe_date='20231114'\n",
    "# task_id = '202310261126558bb8'\n",
    "\n",
    "path = 'outcrapper_raw/photos/'\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if os.path.isfile(path+'/'+f)]\n",
    "files.sort()\n",
    "\n",
    "for file in files:\n",
    "    if '.json' in file and int(file[:8])>=int(scrappe_date):\n",
    "    # if '.json' in file and task_id in file:\n",
    "        print(file)\n",
    "        f = open(f'{path}{file}')\n",
    "        data = json.load(f)\n",
    "        data = pd.json_normalize(data)\n",
    "        \n",
    "        data = data[(data.photo_url.isnull()==False)]\n",
    "        data = data[~data.photo_url_big.str.contains('streetview')]\n",
    "        # data = data[~data.photo_id.isin(existing_list.photo_id)]\n",
    "        \n",
    "        date_str = file[:8]\n",
    "        date_format = '%Y%m%d'\n",
    "        \n",
    "        data['scrappe_date'] = datetime.strptime(date_str, date_format).strftime('%Y-%m-%d')\n",
    "        # data=cleaning_photos(data)\n",
    "\n",
    "        my_schema=[]\n",
    "        save_columns=[]\n",
    "        for column in df_temp.columns :\n",
    "            if column in data.columns :\n",
    "                save_columns.append(column)\n",
    "                my_schema.append(bigquery.SchemaField(column, \"STRING\"))\n",
    "        \n",
    "        # print(len(data[save_columns]))\n",
    "        data[save_columns].to_csv('results/temp_upload_photos.csv',sep=';',index=False)\n",
    "        \n",
    "        # my_schema=[]\n",
    "        # for column in data.columns :\n",
    "        #     my_schema.append(bigquery.SchemaField(column, \"STRING\"))\n",
    "            \n",
    "        #############################################################################################\n",
    "        #BQ DATALAKE HOREGO\n",
    "        src_path_file='results/temp_upload_photos.csv'\n",
    "        target_path_file=f\"scrapping_results/photos/{file.replace('.json','.csv')}\"\n",
    "        bucket_name='horego-bq'\n",
    "        upload_file_to_GCS(horego_key,bucket_name,src_path_file,target_path_file)\n",
    "\n",
    "        table_schema = \"horego_datalake_dev\"\n",
    "        table_name = \"outcrapper_google_photos\"\n",
    "        gcs_path_uri = f\"gs://{bucket_name}/scrapping_results/photos/{file.replace('.json','.csv')}\"\n",
    "        create_table_from_gcs(horego_key,gcs_path_uri,table_schema,table_name,my_schema,'append')\n",
    "        \n",
    "        #############################################################################################\n",
    "        #############################################################################################\n",
    "        #BQ DATALAKE CASHBAC\n",
    "        bucket_name='cashbac_datalake'\n",
    "        src_path_file='results/temp_upload_photos.csv'\n",
    "        target_path_file=f\"scrapping_results/photos/{file.replace('.json','.csv')}\"\n",
    "        upload_file_to_GCS(cashbac_key,bucket_name,src_path_file,target_path_file)\n",
    "\n",
    "        table_schema = \"cashbac_datalake_prod\"\n",
    "        table_name = \"outcrapper_google_photos\"\n",
    "        gcs_path_uri = f\"gs://{bucket_name}/scrapping_results/photos/{file.replace('.json','.csv')}\"\n",
    "        create_table_from_gcs(cashbac_key,gcs_path_uri,table_schema,table_name,my_schema,'append')\n",
    "        #############################################################################################\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f9af0-1347-4ed5-8b7b-c19972613231",
   "metadata": {},
   "source": [
    "### IMPORT TO list_insert_to_prod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017daa12-c180-4be8-a864-2a2a0491b241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24477\n"
     ]
    }
   ],
   "source": [
    "query=f\"\"\" \n",
    "\n",
    "SELECT distinct google_id,place_id\n",
    "FROM `cashbac-31433.cashbac_datalake_prod.vw_outcrapper_google_photos` \n",
    "where scrappe_date >= '{datetime.strptime(scrappe_date, date_format).strftime('%Y-%m-%d')}'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_result = list(cashbac_bqclient.query(query).result(timeout=None))\n",
    "print(len(query_result))\n",
    "if len(query_result)>0:\n",
    "    data = pd.DataFrame(data=[list(x.values()) for x in query_result], columns=list(query_result[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e9a1e5-ef89-4746-a850-e8e0d4225824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "CPU times: user 72.9 ms, sys: 33.8 ms, total: 107 ms\n",
      "Wall time: 826 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query_string=f\"\"\" \n",
    "\n",
    "SELECT column_name\n",
    "FROM cashbac-31433.cashbac_datalake_prod.INFORMATION_SCHEMA.COLUMNS\n",
    "WHERE table_name = 'list_insert_to_prod'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_result = list(cashbac_bqclient.query(query_string).result(timeout=None))\n",
    "print(len(query_result))\n",
    "df_temp = pd.DataFrame(data=[list(x.values()) for x in query_result], columns=list(query_result[0].keys()))\n",
    "\n",
    "my_schema=[]\n",
    "save_columns=[]\n",
    "for column in df_temp.column_name :\n",
    "    if column in data.columns :\n",
    "        save_columns.append(column)\n",
    "        my_schema.append(bigquery.SchemaField(column, \"STRING\"))\n",
    "\n",
    "data[save_columns].drop_duplicates().to_csv('results/input_list_insert_to_prod.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c527f5-f9f4-4f38-9428-767f90c689c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading results/input_list_insert_to_prod.csv\n",
      "Path in GCS: cashbac_datalake/scrapping_results/input_list_insert_to_prod.csv\n",
      "table on : cashbac_datalake_prod.list_insert_to_prod\n"
     ]
    }
   ],
   "source": [
    "cashbac_key='Cashbac-GCP-Keys.json'\n",
    "horego_key='Horego-GCP-Keys.json'\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "# df_temp=pd.read_csv('results/choosen_photos.csv',sep=';', nrows=1)\n",
    "# my_schema=[]\n",
    "# for column in df_temp.columns :\n",
    "#     my_schema.append(bigquery.SchemaField(column, \"STRING\"))\n",
    "\n",
    "src_path_file='results/input_list_insert_to_prod.csv'\n",
    "target_path_file='scrapping_results/input_list_insert_to_prod.csv'\n",
    "bucket_name='cashbac_datalake'\n",
    "upload_file_to_GCS(cashbac_key,bucket_name,src_path_file,target_path_file)\n",
    "\n",
    "table_schema = \"cashbac_datalake_prod\"\n",
    "table_name = \"list_insert_to_prod\"\n",
    "gcs_path_uri = f\"gs://{bucket_name}/scrapping_results/input_list_insert_to_prod.csv\"\n",
    "create_table_from_gcs(cashbac_key,gcs_path_uri,table_schema,table_name,my_schema,'append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
